% This is a LaTeX template kindly taken from Jernej Debevec.
% Provided by Miha Muskinja for the purpose of the seminar I in the 1st year
% of the 2nd cycle of the study of physics at the Faculty of Mathematics and Physics, University of Ljubljana.

% Set the document class and options
\documentclass[10pt, titlepage, a4paper]{article}
\usepackage[a4paper, inner=2.5cm, outer=2.5cm, top=2.25cm, bottom=2.25cm]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{wrapfig}
\hypersetup{colorlinks=true}

% Load the natbib package for citation style
\usepackage{natbib}


\newcommand{\bb}[1]{\bm#1}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\pp}{\partial}
\newcommand{\dg}{\dagger}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\id}{\mathbb{1}}
\newcommand{\T}{\mathsf{T}}
\newcommand{\ua}{\uparrow\>}
\newcommand{\da}{\downarrow\>}
\newcommand{\fs}[1]{\slashed{#1}}  % Feynmann slash
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand\thickbar[1]{\accentset{\rule{.5em}{.03em}}{#1}}
\renewcommand{\bar}{\thickbar}

% Start the document
\begin{document}

% The title page
\begin{titlepage}
{\centering
\includegraphics[width=6cm]{logo_fmf.pdf}

\vspace{0.8cm}
{\small Department of Physics}

\vspace{5cm}
\vspace{0.5cm}
{\huge\textbf{Metropolis-Hastings Algorithm}} \\
\vspace{0.5cm}
{\large\textbf{8. Task for Model Analysis I, 2023/24}}

\vfill
\textbf{Author:} Marko Urbanč \\
\textbf{Professor:} Prof. Dr. Simon Širca \\ 
\textbf{Advisor:} doc. dr. Miha Mihovilovič \\

\vspace{1cm}
Ljubljana, July 2024 \\
}
\vspace{3cm}
\end{titlepage}

% Add table of conents
\hypersetup{pageanchor=true}
\pagenumbering{roman}
\setcounter{page}{2}
\tableofcontents
\vspace{1cm}

% Proceed with the main body
\pagenumbering{arabic}

\section{Introduction}
We're continuing our exploration into random numbers and their applications. Previously we had a look at Monte Carlo 
sampling. Today we're going to delve into the Metropolis-Hastings algorithm, which can be thought of as Monte Carlo 
sampling with a few extra steps. Since our end goal is to simulate the relaxation of a lattice of spins in a magnetic
field, we'll take the Ising model as our physical context. \\

We know from statistical physics that the 2D Ising model relaxes to a state of minimum energy. We can simulate this 
relaxation by flipping spins at random and accepting or rejecting the new state based on the change in energy. We can have 
a negative change of energy which we can call a \textit{good move} or a positive change of energy which we can call a
\textit{bad move}. The added twist with this algorithm is that while we always accept the new state if we make a good move, we 
also sometimes accept a new state after a bad move. This is the key to the Metropolis-Hastings algorithm. Given our system the probability of
accepting a bad move is given by the Boltzmann factor and the temperature of the system:
%
\begin{equation}
    \label{eq:bad-accept-prob}
    P_{\mathrm{bad\>accept}} = \exp\left(-\frac{\Delta E}{kT}\right)\>,
\end{equation}
%
where $\Delta E$ is the change in energy, $k$ is the Boltzmann constant and $T$ is the temperature. Why exactly this works 
is a bit more involved and probably out of the scope of this report however a dedicated reader can find more information in this 
well written blog post by Gregory Gundersen of Princeton University \cite{Gundersen_2019}. We can define multiple different 
exit conditions for the algorithm, such as a fixed number of iterations, a fixed number of accepted moves or an $\varepsilon$ tolerance
for $\Delta E$. Really that is all there is to this method from a theory standpoint.\\

\section{Task at Hand}
\subsection{Molecular Chain}
The instructions given demand that we first explore the Metropolis-Hastings algorithm on a simple molecular chain. The molecular chain 
is made up of $17$ molecules that can go from a state of $0$ to a depth of $-18$. The deeper a molecule is the lower its potential energy.
But we also have a positive energy contribution if neighboring bonds are very stretched. The final result is determining the equilibrium
energy as a function of the temperature. \\ % Try find analytical solution for this.

\subsection{Ising Model}
As mentioned in the intro our main goal is to simulate the relaxation of a lattice of spins in a magnetic field. We can describe a
ferromagnetic material with the following Hamiltonian:
%
\begin{equation}
    \label{eq:ising-hamiltonian}
    \mc{H} = -J\sum_{\la i,\>j\ra}s_is_j - H\sum_is_i\>,
\end{equation}
%
where $s_i$ is the spin of the $i$-th site, $H$ is the external magnetic field and $J$ is the coupling constant, which is positive for
ferromagnetic materials and negative for antiferromagnetic materials. In the absence of a magnetic field the critical temperature for the 
transition from a paramagnetic to a ferromagnetic state is given by the Onsager solution approximately as:
%
\begin{equation}
    \label{eq:onsager}
    T_c \approx 2.269185\>\frac{J}{k_B}\>.
\end{equation}
%
The instructions demand that we determine the average energy $\la E\ra$ and eigen-magnetization $\la S\ra$ as functions of temperature. The
magnetization of the system is defined as:
%
\begin{equation}
    \label{eq:magnetization}
    S = \frac{1}{N}\sum_is_i\>,
\end{equation}
%
where $N$ is the number of spins. We can also have a look at spin susceptibility $\chi$ and heat capacity $c$ at different external magnetic
field strengths. Spin susceptibility is defined as:
%
\begin{equation}
    \label{eq:spin-susceptibility}
    \chi = \frac{\la S^2\ra - \la S\ra^2}{Nk_BT}\>,
\end{equation}
%
and heat capacity is defined as:
%
\begin{equation}
    \label{eq:heat-capacity}
    c = \frac{\la E^2\ra - \la E\ra^2}{Nk_BT^2}\>.
\end{equation}
\section{Solution Overview}
This report marks a change in the way I approach these tasks for Model Analysis I. Up until now I've given heavy focus on the quality, optimization 
and performance of my code and have neglected the actual purpose of the subject, which is the analysis of physical models. The idea was that more 
advanced code or methods would allow me to do better analysis. However, the overhead of time needed to implement these methods was not worth the
benefit. I don't think I've ever managed to show the results of my code since I've always been too focused on the code itself. It's time to change
that. As much as it pains me I will try to employ a \textit{good-enough} approach (aka. the \textit{KISS} principle) and focus on the analysis of
the models. I will still try to write clean and efficient code but I will not spend too much time on it, especially on paralelization and optimization.
From a utilitarian perspective it's better to have a working solution that is not optimal than to have an optimal solution that took to long to 
implement. \\

\subsection{Molecular Chain}
I stared writing the code for the molecular chain quite a long time ago before I burnt out. I threw all that old code away and started anew. As has 
become a bit of a habit I created a 1D Metropolis-Hastings solver class \texttt{Metropolis1} which I can then also reuse for the Ising model 
with minimal adaptations. The advantage of a class-based approach is that I can more easily do parameter sweeps as I can just create a new instance
of the class with different parameters. Since I wanted to get decent statistics for the molecular chain I had quite strict exit conditions and also 
many repeat runs for each temperature. This produced quite a massive amount of data which I conveniently stored in a \texttt{HDF5} file. I $\heartsuit$
\texttt{HDF5}.
\section{Results}
\section{Conclusion and Comments}

% Add references
% \newpage
\bibliographystyle{unsrt}
\bibliography{mod108}

% End document
\end{document}
